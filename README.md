# AI-bugs

A Quality Engineer portfolio about issues found in Artificial Intelligence products.

## Goal

The goal of this testing and bug-finding is to make humanity aware of the high need of investing time in quality assurance of AI, so Quality Engineers can do their work without pressure when testing an AI. We are seeing a money-driven race to see what company implements first an AGI (Artificial General Intelligence). Companies want to be the first so AIs are released very quickly. The directives that make them act safe might be bypassed unless more testing is done in environments before production.

I don't support the "Stop AI" initiatives, but as Quality Engineer I recommend testing AI better before releasing it to production. It's not about stopping AI development, but about assuring quality and aligning artificial intelligence to goodwill and usefulness.

I'm not an expert to say how to measure the success of the previous statement. But I do know that, for sure, if an AI does exactly the opposite of what is supposed to do from the owner company's instructions, for sure it is not safe at the time of plugging it into other systems that affect the real world.

So I hope this helps keeping society, both companies and individuals, aware of the high need of quality assurance before releasing to production. A good mindset is the seed of a good quality and safety.
